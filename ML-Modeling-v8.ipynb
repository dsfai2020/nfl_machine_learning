{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Modeling - NFL data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries (comment / uncomment Tensorflow, until fixed)\n",
    "\n",
    "Problems with Tensorflow (for Neural Network):\n",
    "\n",
    "* Had to set up separate environment within Anaconda for it. Some other modules, like beautifulsoup weren't supported and other modules had compatibility problems in that environment.\n",
    "* Could not pickle the Tensorflow model for the Predict script.\n",
    "\n",
    "Switched to sklearn NN; see: https://blog.eduonix.com/artificial-intelligence/explore-neural-networks-scikit-learn/\n",
    "\n",
    "NN modeling: https://machinelearningmastery.com/how-to-configure-the-number-of-layers-and-nodes-in-a-neural-network/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import  StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.externals import joblib  \n",
    "import pickle\n",
    "\n",
    "# import tensorflow as tf\n",
    "# tf.logging.set_verbosity(tf.logging.ERROR)     # only display errors\n",
    "\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = 'Notes: '                 # concatenate notes to this string for report, proceed each by ' **'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = 13                   # this is feature set # to access the feature set stored in testdb\n",
    "saveRpt = 'Y'                   # Y/N to save report to testdb\n",
    "alg = 'NN'                      # algorithmn to use (LR, LR-PCA, NN, RFC, LR-RFE, ETC, SVM, SVMgrid)\n",
    "save_model = 'Y'                # Y/N to save model for production predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This section includes all the functions to do algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Logical Regression, w/o PCA\n",
    "def LogRegNoPCA(xtrain,ytrain, xtest,ytest,xnote, featList):\n",
    "\n",
    "    logmodel = LogisticRegression(solver='lbfgs')\n",
    "    logmodel.fit(xtrain,ytrain)\n",
    "    y_testpredict = logmodel.predict(xtest)\n",
    "    x_trainpredict = logmodel.predict(xtrain)\n",
    "\n",
    "    score = 0\n",
    "    bestC = 999\n",
    "    # C values: Inverse of regularization strength; smaller values specify stronger regularization\n",
    "    for C_option in [.001,.50,.60,.70,.80, .85,.90,.95, 1, 1.05, 2, 5, 100]:\n",
    "        logregC = LogisticRegression(C=C_option, solver='lbfgs').fit(xtrain, ytrain)\n",
    "        if  logregC.score(xtest, ytest) > score:\n",
    "            score = logregC.score(xtest, ytest)\n",
    "            logmodel = logregC\n",
    "            bestC = C_option      \n",
    "            \n",
    "    xnote = xnote + ' ** C selected, C = ' + str(bestC) + '; score (%):' + str(round(score,2)*100)     \n",
    "        \n",
    "    return y_testpredict,x_trainpredict,logmodel,xnote \n",
    "\n",
    "\n",
    "#### Logical Regression, w/ Recursive Feature Elimination\n",
    "def LogRegRFE(xtrain,ytrain, xtest,ytest,xnote, featList):\n",
    "    \n",
    "    # create a base classifier used to evaluate a subset of attributes\n",
    "    logmodel = LogisticRegression(solver='lbfgs')\n",
    "    # create the RFE model and select n attributes\n",
    "    num_attr = 10              # number of attributes\n",
    "    rfe = RFE(logmodel, num_attr)\n",
    "    rfe = rfe.fit(xtrain, ytrain)\n",
    "    # summarize the selection of the attributes\n",
    "    support = rfe.support_\n",
    "    ranking = rfe.ranking_\n",
    "           \n",
    "    featureDF = pd.DataFrame({'Feature': featList, 'Support': support, 'Ranking': ranking})\n",
    "    featureDF = featureDF.sort_values(\"Ranking\", ascending=[True])\n",
    "    print('Feature Analysis (contributors):\\n', featureDF)\n",
    "    \n",
    "    y_testpredict = rfe.predict(xtest)\n",
    "    x_trainpredict = rfe.predict(xtrain)\n",
    "            \n",
    "    xnote = xnote + ' ** RFE # of attributes: ' + str(num_attr)      \n",
    "        \n",
    "    return y_testpredict,x_trainpredict,rfe,xnote \n",
    "\n",
    "\n",
    "\n",
    "#### Logical Regression, w/ PCA\n",
    "def LogRegPCA(xtrain,ytrain, xtest,xnotes):\n",
    "    # Make an instance of the Model\n",
    "    pca = PCA(.95)                      # alternatively, could force to n PCs; e.g. pca = PCA(2)\n",
    "    pca.fit(xtrain)                            # fit the Scaled features\n",
    "    xnotes = xnotes + ' ** PCA components:' + str(pca.n_components_ )\n",
    "    \n",
    "    X_trainP = pca.transform(xtrain)       # this creates the PCA components (new / composite features)\n",
    "    X_testP = pca.transform(xtest)\n",
    "    \n",
    "    logR_PCA = LogisticRegression()                     # set up instance (model)\n",
    "    logR_PCA.fit(X_trainP, ytrain)                     # fit training data\n",
    "\n",
    "    y_testpredict = logR_PCA.predict(X_testP)                     # predict all test cases\n",
    "    x_trainpredict = logR_PCA.predict(X_trainP)                     # predict all training cases\n",
    "    \n",
    "    print(\"PCA explained variance:\\n\", pca.explained_variance_ratio_)\n",
    "    \n",
    "    return y_testpredict,x_trainpredict,logR_PCA, xnotes\n",
    "\n",
    "#### Support Vector Machine, No Grid\n",
    "def SVM(xtrain,ytrain, xtest,ytest,xnote, featList):\n",
    "\n",
    "    svc_model = SVC()\n",
    "    svc_model.fit(xtrain,ytrain)\n",
    "    y_testpredict = svc_model.predict(xtest)\n",
    "    x_trainpredict = svc_model.predict(xtrain)\n",
    "\n",
    "    xnote = xnote + ' ** SVM selected. No Grid.'        \n",
    "    return y_testpredict,x_trainpredict,svc_model,xnote \n",
    "\n",
    "#### Support Vector Machine, w Grid\n",
    "def SVMgrid(xtrain,ytrain, xtest,ytest,xnote, featList):\n",
    "\n",
    "    svc_model = SVC()\n",
    "    svc_model.fit(xtrain,ytrain)\n",
    "    y_testpredict = svc_model.predict(xtest)\n",
    "    x_trainpredict = svc_model.predict(xtrain)\n",
    "    \n",
    "    # Grid Search\n",
    "    param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001]}\n",
    "    grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\n",
    "    grid.fit(xtrain,ytrain)\n",
    "    \n",
    "    y_testpredict  = grid.predict(xtest)\n",
    "    x_trainpredict  = grid.predict(xtrain)\n",
    "\n",
    "    xnote = xnote + ' ** SVM selected. With Grid'        \n",
    "    return y_testpredict,x_trainpredict,grid,xnote \n",
    "\n",
    "#### Extra Trees Classifier\n",
    "def ExtraTrees(xtrain,ytrain, xtest,ytest,xnote, featList):\n",
    "    \n",
    "    # create a base classifier used to evaluate    \n",
    "    ETCmodel = ExtraTreesClassifier()\n",
    "    ETCmodel.fit(xtrain, ytrain)\n",
    "    \n",
    "    # display the relative importance of each attribute\n",
    "\n",
    "    importances = ETCmodel.feature_importances_\n",
    "    featureDF = pd.DataFrame({'Feature': featList, 'Importance': importances})\n",
    "    featureDF['Importance'] = featureDF['Importance'].apply(lambda x: round(x*100,2))\n",
    "    featureDF = featureDF.sort_values(\"Importance\", ascending=[False])\n",
    "    print('Feature Analysis (contributors) in %:\\n', featureDF)\n",
    "    \n",
    "    y_testpredict = ETCmodel.predict(xtest)\n",
    "    x_trainpredict = ETCmodel.predict(xtrain)\n",
    "            \n",
    "    xnote = xnote + ' ** ETC - see feature analysis. '      \n",
    "        \n",
    "    return y_testpredict,x_trainpredict,ETCmodel,xnote \n",
    "\n",
    "\n",
    "#### Random Forest Classifier\n",
    "def RFC(xtrain,ytrain, xtest,xnotes, featList):\n",
    "    estimators = 101               # Number of trees in forest; default = 100\n",
    "    \n",
    "    #  oob: use out-of-bag (OOB) samples to estimate the generalization accuracy (default = False)\n",
    "    #  verbose : int, optional (default=0); Controls the verbosity when fitting and predicting\n",
    "    rfcmodel = RandomForestClassifier(n_estimators=estimators, random_state=242, oob_score=True)\n",
    "    rfcmodel.fit(xtrain, ytrain)\n",
    "    y_testpredict = rfcmodel.predict(xtest)      # predict test data with model\n",
    "    x_trainpredict = rfcmodel.predict(xtrain)    # predict train data with model\n",
    "    \n",
    "\n",
    "    importances = rfcmodel.feature_importances_\n",
    "    featureDF = pd.DataFrame({'Feature': featList, 'Importance': importances})\n",
    "    featureDF['Importance'] = featureDF['Importance'].apply(lambda x: round(x*100,2))\n",
    "    featureDF = featureDF.sort_values(\"Importance\", ascending=[False])\n",
    "    print('Feature Analysis (contributors) in %:\\n', featureDF)\n",
    " \n",
    "\n",
    "    \n",
    "    xnotes = xnotes + ' ** RF classifier, estimators:' + str(estimators) + '  oob_score = True'\n",
    "\n",
    "    return y_testpredict,x_trainpredict,rfcmodel,xnotes \n",
    "\n",
    "#### Neural Network, w/o PCA\n",
    "def NN(xtrain,ytrain, xtest,xnotes):\n",
    "    ## The MLPClassifier and MLPRegressor are sklearn implementations of NNs\n",
    "\n",
    "    # need to model output as an number 0/1  (make a copy; don't modify existing ytrain)\n",
    "    print('ytrain:', len(ytrain),  type(ytrain))\n",
    "    print('xtrain:', len(xtrain),  type(xtrain))    \n",
    "\n",
    "    ytrainx = pd.Series(ytrain.values.copy('C'),index=ytrain.index, name = ytrain.name)\n",
    "     \n",
    "    print('ytrainx:', len(ytrainx), type(ytrainx))\n",
    "    for i in range(len(ytrain)):            \n",
    "        if ytrain.iloc[i] == 'A':            # A (home team) will be one; B (away team) will be zero\n",
    "            ytrainx.iloc[i] = 1\n",
    "        else: ytrainx.iloc[i] = 0\n",
    "\n",
    "    #### added   https://www.kaggle.com/hhllcks/neural-net-with-gridsearch\n",
    "    grid_search = 'n'\n",
    "    if grid_search == 'y':\n",
    "        mlp = MLPClassifier()\n",
    "        parameters = {'solver': ['lbfgs'], 'max_iter': [100,500, 800], 'alpha': 10.0 ** -np.arange(1, 7),\n",
    "                      'hidden_layer_sizes':np.arange(5, 12), 'random_state':[0,1,2]}\n",
    "        # hidden_layer_sizes':np.arange(5, 12) gives [ 5  6  7  8  9 10 11]  \n",
    "        gs = GridSearchCV(mlp, parameters)\n",
    "        gs.fit(xtrain, ytrain)\n",
    "        y_testpredictN = gs.predict(xtest)                  # will give 0s and 1s\n",
    "        y_trainpredictN = gs.predict(xtrain)                # will give 0s and 1s\n",
    "        print('Params:', gs.get_params(deep=True))\n",
    "    else:\n",
    "        # Alogorithm will generate input layer (nodes= # features) and output layers (=1, since binary prediction)\n",
    "        hidden_layers=[12,8]  # define the layers/depth of the NN\n",
    "        print(\"Creating a neural network with \"+str(len(hidden_layers))+\" layers and \"+str(2000)+\" iterations\")\n",
    "        xnotes = xnotes + ' ** NN, # of layers:' + str(len(hidden_layers)) + ' Nodes/layer:' + str([x for x in hidden_layers])\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(hidden_layers),activation='relu', \n",
    "                            alpha = .0001, max_iter=2000, random_state=10, solver = 'adam') \n",
    "\n",
    "        # an object which represents the neural network\n",
    "        # Remember to use the pre-processed data and not original values for fit()\n",
    "\n",
    "        mlp.fit(xtrain, ytrainx)  # fit features over NN\n",
    "        # predict for both training and testing\n",
    "        y_testpredictN = mlp.predict(xtest)                  # will give 0s and 1s\n",
    "        y_trainpredictN = mlp.predict(xtrain)                # will give 0s and 1s\n",
    "        print('Params:', mlp.get_params(deep=True))\n",
    "        \n",
    "              # change 0/1 to A/B for test data\n",
    "    ydf1 = pd.DataFrame(y_testpredictN, columns=['Num-NN'])\n",
    "    ydf1.head(2)\n",
    "    ydf1['AB-NN'] = np.where(ydf1['Num-NN'] == 1 , 'A', 'B')\n",
    "    print('\\nTest ydf1 : ', ydf1.shape)\n",
    "    y_testpredict = ydf1['AB-NN']\n",
    "              # change 0/1 to A/B for train data\n",
    "    ydf = pd.DataFrame(y_trainpredictN, columns=['Num-NN'])\n",
    "    ydf['AB-NN'] = np.where(ydf['Num-NN'] ==1 , 'A', 'B')\n",
    "    print('\\nTrain ydf : ', ydf.shape)\n",
    "    y_trainpredict = ydf['AB-NN']             \n",
    "    \n",
    "    return y_testpredict, y_trainpredict, mlp, xnotes\n",
    "\n",
    "\n",
    "# y_testPredict,x_trainPredict,model,notes = NN(X_train,y_train, X_test, notes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to TestDB so that test results can be recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database created: TestDB.sqlite ;  Sqlite3 version: 2.6.0\n"
     ]
    }
   ],
   "source": [
    "# Connect to database\n",
    "def create_connection(db_file):\n",
    "    \"\"\" \n",
    "    Create a database connection to a SQLite database.\n",
    "    Note: When you connect to an SQLite database file that does not exist, SQLite creates a new database.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        print('Database created:', db_file, ';  Sqlite3 version:', sqlite3.version)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "TestDB = \"TestDB.sqlite\"\n",
    "create_connection(TestDB)\n",
    "conn = sqlite3.connect(TestDB)         # make  “connection” to the database\n",
    "cur = conn.cursor()                            # cursor is like a ﬁle handle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data; create X and y sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of games in (InCnt): 146\n",
      "Columns: ['Year', 'Wk', 'Game', 'Ateam', 'Awin', 'AwinH', 'AptsPos', 'AptsNeg', 'AqbrTot', 'AqbPts', 'AqbPass', 'AqbRun', 'AL5WinR', 'AL5PtsP', 'AL5PtsN', 'AL5Qtr4', 'AL5upSp', 'AL5upSn', 'AoScore', 'AdScore', 'AimpactS1', 'AimpactN1', 'AimpactS2', 'AimpactN2', 'AupSpH', 'AupSnH', 'ATOnet', 'ATOpos', 'ATOneg', 'ApenNegCnt', 'ApenNegYds', 'ApenPosCnt', 'ApenPosYds', 'Aplays', 'AFGgood', 'AFG50plus', 'Bteam', 'Bwin', 'BwinA', 'BptsPos', 'BptsNeg', 'BqbrTot', 'BqbPts', 'BqbPass', 'BqbRun', 'BL5WinR', 'BL5PtsP', 'BL5PtsN', 'BL5upSp', 'BL5upSn', 'BL5Qtr4', 'BoScore', 'BdScore', 'BimpactS1', 'BimpactN1', 'BimpactS2', 'BimpactN2', 'BupSpA', 'BupSnA', 'BTOnet', 'BTOpos', 'BTOneg', 'BpenNegCnt', 'BpenNegYds', 'BpenPosCnt', 'BpenPosYds', 'Bplays', 'BFGgood', 'BFG50plus', 'winner']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Wk</th>\n",
       "      <th>Game</th>\n",
       "      <th>Ateam</th>\n",
       "      <th>Awin</th>\n",
       "      <th>AwinH</th>\n",
       "      <th>AptsPos</th>\n",
       "      <th>AptsNeg</th>\n",
       "      <th>AqbrTot</th>\n",
       "      <th>AqbPts</th>\n",
       "      <th>...</th>\n",
       "      <th>BTOpos</th>\n",
       "      <th>BTOneg</th>\n",
       "      <th>BpenNegCnt</th>\n",
       "      <th>BpenNegYds</th>\n",
       "      <th>BpenPosCnt</th>\n",
       "      <th>BpenPosYds</th>\n",
       "      <th>Bplays</th>\n",
       "      <th>BFGgood</th>\n",
       "      <th>BFG50plus</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Panthers</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.625</td>\n",
       "      <td>376</td>\n",
       "      <td>-382</td>\n",
       "      <td>55.6</td>\n",
       "      <td>13.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>-7.3</td>\n",
       "      <td>-60.9</td>\n",
       "      <td>7.9</td>\n",
       "      <td>72.2</td>\n",
       "      <td>181.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Ravens</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.75</td>\n",
       "      <td>389</td>\n",
       "      <td>-287</td>\n",
       "      <td>57.3</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>-6.3</td>\n",
       "      <td>-49.1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>49.4</td>\n",
       "      <td>171.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year Wk Game     Ateam   Awin  AwinH AptsPos AptsNeg AqbrTot AqbPts  ...  \\\n",
       "0  2019  2    1  Panthers  0.438  0.625     376    -382    55.6   13.3  ...   \n",
       "1  2019  2    2    Ravens  0.625   0.75     389    -287    57.3     11  ...   \n",
       "\n",
       "  BTOpos BTOneg BpenNegCnt BpenNegYds BpenPosCnt BpenPosYds Bplays BFGgood  \\\n",
       "0    1.1   -2.2       -7.3      -60.9        7.9       72.2  181.4     0.1   \n",
       "1      1   -1.8       -6.3      -49.1        6.2       49.4  171.5     0.1   \n",
       "\n",
       "  BFG50plus winner  \n",
       "0       0.1      B  \n",
       "1       0.1      A  \n",
       "\n",
       "[2 rows x 70 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "project = 'ai_affinity; nfl'                   # this is same for all of our NFL tests\n",
    "mdf = pd.read_pickle('mdftemp')\n",
    "inCnt = len(mdf)\n",
    "print(\"Number of games in (InCnt):\", inCnt)\n",
    "print('Columns:', mdf.columns.tolist())\n",
    "mdf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4       True\n",
      "       ...  \n",
      "141    False\n",
      "142    False\n",
      "143    False\n",
      "144    False\n",
      "145    False\n",
      "Name: Ateam, Length: 146, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#############  ADJUSTMENTS     #######\n",
    "print(mdf['Ateam']== 'Steelers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Years in input: [2019]   Weeks: [2 3 4 5 6 7 8 9 10 11]\n"
     ]
    }
   ],
   "source": [
    "# Data characteristics\n",
    "Years = mdf['Year'].unique()\n",
    "Weeks = mdf['Wk'].unique()\n",
    "print ('Years in input:', Years,'  Weeks:', Weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Rows dropped due to missing (NaN): 0\n"
     ]
    }
   ],
   "source": [
    "# Any null values (need to eliminate due to normalization)  --- data should be clean\n",
    "tempL = len(mdf)            \n",
    "mdf = mdf.dropna()     # drop missing, nan, etc\n",
    "print (' *** Rows dropped due to missing (NaN):', tempL - len(mdf)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "Feature Sets (list of features to use) are stored in the TestDB in the featureSet table.\n",
    "Use the featureSet table as the master copy (retrive and use it here).\n",
    "Manually create new feature sets in the featureSet table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature list length: 64 Features: ['Awin', 'AwinH', 'AptsPos', 'AptsNeg', 'AqbrTot', 'AqbPts', 'AqbPass', 'AqbRun', 'AL5WinR', 'AL5PtsP', 'AL5PtsN', 'AL5Qtr4', 'AL5upSp', 'AL5upSn', 'AoScore', 'AdScore', 'AimpactS1', 'AimpactN1', 'AimpactS2', 'AimpactN2', 'AupSpH', 'AupSnH', 'Aplays', 'ApenNegCnt', 'ApenNegYds', 'ApenPosCnt', 'ApenPosYds', 'ATOnet', 'ATOpos', 'ATOneg', 'AFGgood', 'AFG50plus', 'Bwin', 'BwinA', 'BptsPos', 'BptsNeg', 'BqbrTot', 'BqbPts', 'BqbPass', 'BqbRun', 'BL5WinR', 'BL5PtsP', 'BL5PtsN', 'BL5Qtr4', 'BL5upSp', 'BL5upSn', 'BoScore', 'BdScore', 'BimpactS1', 'BimpactN1', 'BimpactS2', 'BimpactN2', 'BupSpA', 'BupSnA', 'Bplays', 'BpenNegCnt', 'BpenNegYds', 'BpenPosCnt', 'BpenPosYds', 'BTOnet', 'BTOpos', 'BTOneg', 'BFGgood', 'BFG50plus']\n",
      "   Year winner\n",
      "0  2019      B\n",
      "1  2019      A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Awin</th>\n",
       "      <th>AwinH</th>\n",
       "      <th>AptsPos</th>\n",
       "      <th>AptsNeg</th>\n",
       "      <th>AqbrTot</th>\n",
       "      <th>AqbPts</th>\n",
       "      <th>AqbPass</th>\n",
       "      <th>AqbRun</th>\n",
       "      <th>AL5WinR</th>\n",
       "      <th>AL5PtsP</th>\n",
       "      <th>...</th>\n",
       "      <th>Bplays</th>\n",
       "      <th>BpenNegCnt</th>\n",
       "      <th>BpenNegYds</th>\n",
       "      <th>BpenPosCnt</th>\n",
       "      <th>BpenPosYds</th>\n",
       "      <th>BTOnet</th>\n",
       "      <th>BTOpos</th>\n",
       "      <th>BTOneg</th>\n",
       "      <th>BFGgood</th>\n",
       "      <th>BFG50plus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.438</td>\n",
       "      <td>0.625</td>\n",
       "      <td>376</td>\n",
       "      <td>-382</td>\n",
       "      <td>55.6</td>\n",
       "      <td>13.3</td>\n",
       "      <td>41.7</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>19.8</td>\n",
       "      <td>...</td>\n",
       "      <td>181.4</td>\n",
       "      <td>-7.3</td>\n",
       "      <td>-60.9</td>\n",
       "      <td>7.9</td>\n",
       "      <td>72.2</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.75</td>\n",
       "      <td>389</td>\n",
       "      <td>-287</td>\n",
       "      <td>57.3</td>\n",
       "      <td>11</td>\n",
       "      <td>30.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30.2</td>\n",
       "      <td>...</td>\n",
       "      <td>171.5</td>\n",
       "      <td>-6.3</td>\n",
       "      <td>-49.1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>49.4</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.438</td>\n",
       "      <td>0.375</td>\n",
       "      <td>281</td>\n",
       "      <td>-359</td>\n",
       "      <td>49.4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>17.8</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>173.8</td>\n",
       "      <td>-6.3</td>\n",
       "      <td>-52.7</td>\n",
       "      <td>5.4</td>\n",
       "      <td>42.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Awin  AwinH AptsPos AptsNeg AqbrTot AqbPts AqbPass AqbRun AL5WinR AL5PtsP  \\\n",
       "0  0.438  0.625     376    -382    55.6   13.3    41.7    8.4     0.2    19.8   \n",
       "1  0.625   0.75     389    -287    57.3     11    30.1    2.9     0.8    30.2   \n",
       "2  0.438  0.375     281    -359    49.4    4.6    17.8    5.5     0.2      15   \n",
       "\n",
       "   ... Bplays BpenNegCnt BpenNegYds BpenPosCnt BpenPosYds BTOnet BTOpos  \\\n",
       "0  ...  181.4       -7.3      -60.9        7.9       72.2   -1.1    1.1   \n",
       "1  ...  171.5       -6.3      -49.1        6.2       49.4   -0.8      1   \n",
       "2  ...  173.8       -6.3      -52.7        5.4       42.1    0.2    1.2   \n",
       "\n",
       "  BTOneg BFGgood BFG50plus  \n",
       "0   -2.2     0.1       0.1  \n",
       "1   -1.8     0.1       0.1  \n",
       "2   -1.1    0.81      0.86  \n",
       "\n",
       "[3 rows x 64 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select Feature List\n",
    "\n",
    "cur.execute('SELECT fsSet From featureSet WHERE fsNum = ?', ( features,))\n",
    "feat_str = cur.fetchone()[0]\n",
    "feat_list = feat_str.split(',')\n",
    "print('\\nFeature list length:', len(feat_list),'Features:',  feat_list)\n",
    "\n",
    "Num_of_feat= len(feat_list)\n",
    "\n",
    "X = mdf[feat_list]\n",
    "y = mdf[['Year','winner']]\n",
    "print(y.head(2))\n",
    "X.head(3)\n",
    "\n",
    "# print(X.loc[0:5,['AptsNeg', 'AL5PtsN','AupSnH','AL5upSn']])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized the data, as appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rernst\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\rernst\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Awin</th>\n",
       "      <th>AwinH</th>\n",
       "      <th>AptsPos</th>\n",
       "      <th>AptsNeg</th>\n",
       "      <th>AqbrTot</th>\n",
       "      <th>AqbPts</th>\n",
       "      <th>AqbPass</th>\n",
       "      <th>AqbRun</th>\n",
       "      <th>AL5WinR</th>\n",
       "      <th>AL5PtsP</th>\n",
       "      <th>...</th>\n",
       "      <th>Bplays</th>\n",
       "      <th>BpenNegCnt</th>\n",
       "      <th>BpenNegYds</th>\n",
       "      <th>BpenPosCnt</th>\n",
       "      <th>BpenPosYds</th>\n",
       "      <th>BTOnet</th>\n",
       "      <th>BTOpos</th>\n",
       "      <th>BTOneg</th>\n",
       "      <th>BFGgood</th>\n",
       "      <th>BFG50plus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.485087</td>\n",
       "      <td>3.053798</td>\n",
       "      <td>4.984375</td>\n",
       "      <td>-7.545538</td>\n",
       "      <td>4.681687</td>\n",
       "      <td>0.564561</td>\n",
       "      <td>1.519625</td>\n",
       "      <td>1.261873</td>\n",
       "      <td>0.708932</td>\n",
       "      <td>3.536615</td>\n",
       "      <td>...</td>\n",
       "      <td>38.625577</td>\n",
       "      <td>-10.646226</td>\n",
       "      <td>-10.189863</td>\n",
       "      <td>10.389574</td>\n",
       "      <td>10.068417</td>\n",
       "      <td>-1.889635</td>\n",
       "      <td>2.894521</td>\n",
       "      <td>-6.289823</td>\n",
       "      <td>0.323513</td>\n",
       "      <td>0.355918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.546072</td>\n",
       "      <td>3.664558</td>\n",
       "      <td>5.156707</td>\n",
       "      <td>-5.669030</td>\n",
       "      <td>4.824832</td>\n",
       "      <td>0.466930</td>\n",
       "      <td>1.096900</td>\n",
       "      <td>0.435647</td>\n",
       "      <td>2.835728</td>\n",
       "      <td>5.394231</td>\n",
       "      <td>...</td>\n",
       "      <td>36.517566</td>\n",
       "      <td>-9.187839</td>\n",
       "      <td>-8.215472</td>\n",
       "      <td>8.153843</td>\n",
       "      <td>6.888917</td>\n",
       "      <td>-1.374280</td>\n",
       "      <td>2.631383</td>\n",
       "      <td>-5.146218</td>\n",
       "      <td>0.323513</td>\n",
       "      <td>0.355918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.485087</td>\n",
       "      <td>1.832279</td>\n",
       "      <td>3.725025</td>\n",
       "      <td>-7.091226</td>\n",
       "      <td>4.159628</td>\n",
       "      <td>0.195262</td>\n",
       "      <td>0.648665</td>\n",
       "      <td>0.826227</td>\n",
       "      <td>0.708932</td>\n",
       "      <td>2.679254</td>\n",
       "      <td>...</td>\n",
       "      <td>37.007306</td>\n",
       "      <td>-9.187839</td>\n",
       "      <td>-8.817829</td>\n",
       "      <td>7.101734</td>\n",
       "      <td>5.870919</td>\n",
       "      <td>0.343570</td>\n",
       "      <td>3.157659</td>\n",
       "      <td>-3.144911</td>\n",
       "      <td>2.620453</td>\n",
       "      <td>3.060899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Awin     AwinH   AptsPos   AptsNeg   AqbrTot    AqbPts   AqbPass  \\\n",
       "0  2.485087  3.053798  4.984375 -7.545538  4.681687  0.564561  1.519625   \n",
       "1  3.546072  3.664558  5.156707 -5.669030  4.824832  0.466930  1.096900   \n",
       "2  2.485087  1.832279  3.725025 -7.091226  4.159628  0.195262  0.648665   \n",
       "\n",
       "     AqbRun   AL5WinR   AL5PtsP  ...     Bplays  BpenNegCnt  BpenNegYds  \\\n",
       "0  1.261873  0.708932  3.536615  ...  38.625577  -10.646226  -10.189863   \n",
       "1  0.435647  2.835728  5.394231  ...  36.517566   -9.187839   -8.215472   \n",
       "2  0.826227  0.708932  2.679254  ...  37.007306   -9.187839   -8.817829   \n",
       "\n",
       "   BpenPosCnt  BpenPosYds    BTOnet    BTOpos    BTOneg   BFGgood  BFG50plus  \n",
       "0   10.389574   10.068417 -1.889635  2.894521 -6.289823  0.323513   0.355918  \n",
       "1    8.153843    6.888917 -1.374280  2.631383 -5.146218  0.323513   0.355918  \n",
       "2    7.101734    5.870919  0.343570  3.157659 -3.144911  2.620453   3.060899  \n",
       "\n",
       "[3 rows x 64 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Try different scalers and options.\n",
    "#### scaler = MinMaxScaler(feature_range=(-1, 1))      # default is feature_range=(0, 1)\n",
    "scaler = StandardScaler(with_mean= False)                # mean of zero\n",
    "cols = X.columns.tolist()\n",
    "Xscale = pd.DataFrame(scaler.fit_transform(X), columns=cols)\n",
    "print(Xscale.shape)\n",
    "Xscale.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Training and Test datasets by Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training and Test datasets (Special Option or Traditional Option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (146, 64) <class 'pandas.core.frame.DataFrame'>\n",
      "y: (146,) <class 'pandas.core.series.Series'>\n",
      "Number of Training games: 97 Test games: 49\n",
      "X_train shape: (97, 64) <class 'pandas.core.frame.DataFrame'>\n",
      "y_train: 97 <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "#            Special: Separate Training and Test data by Years \n",
    "special = 'no'\n",
    "test_percent=.33                   # used in Traditional Approach (not the special)\n",
    "\n",
    "if special == 'yes':                   ##### SPECIAL APPROACH (by year)\n",
    "    split_year = 2017\n",
    "    notes = notes + '**  Train / Test Split special: ' + str(split_year)\n",
    "    Xscale['Year'] = mdf['Year']\n",
    "    X_train = Xscale[(Xscale['Year'] < split_year)]    \n",
    "    X_test = Xscale[(Xscale['Year'] >= split_year)]\n",
    "    X_train.drop('Year', axis=1,inplace=True)\n",
    "    X_test.drop('Year', axis=1,inplace=True)\n",
    "\n",
    "    y['Year'] = mdf['Year']\n",
    "    print('y:', y.shape, type(y))\n",
    "    y_train= y[(y['Year'] < split_year)]\n",
    "    y_test = y[(y['Year'] >= split_year)]\n",
    "    y_train.drop('Year', axis=1,inplace=True)\n",
    "    y_test = y_test['winner']\n",
    "\n",
    "    print('X_train shape:', X_train.shape, type(X_train))\n",
    "    print('y_train:', len(y_train), type(y_train) )\n",
    "    y_train = y_train['winner']  #convert to series\n",
    "    ydf = pd.DataFrame(y_train)\n",
    "\n",
    "else:                                   ##### TRADITIONAL APPROACH (using algorithm)\n",
    "    y = mdf['winner']\n",
    "    notes = notes + '** Train / Test Split traditional at: ' + str(test_percent)\n",
    "    print('X:', Xscale.shape, type(X))\n",
    "    print('y:', y.shape, type(y))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Xscale, y, test_size=test_percent, random_state=42)\n",
    "    print('Number of Training games:', len(X_train), 'Test games:', len(X_test))\n",
    "    print('X_train shape:', X_train.shape, type(X_train))\n",
    "    print('y_train:', len(y_train), type(y_train) )\n",
    "    ydf = pd.DataFrame(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Create Model and Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ytrain: 97 <class 'pandas.core.series.Series'>\n",
      "xtrain: 97 <class 'pandas.core.frame.DataFrame'>\n",
      "ytrainx: 97 <class 'pandas.core.series.Series'>\n",
      "Creating a neural network with 2 layers and 2000 iterations\n",
      "Params: {'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': [12, 8], 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_iter': 2000, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 10, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n",
      "\n",
      "Test ydf1 :  (49, 2)\n",
      "\n",
      "Train ydf :  (97, 2)\n",
      "Notes: ** Train / Test Split traditional at: 0.33 ** NN, # of layers:2 Nodes/layer:[12, 8]\n",
      "model type: <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>\n"
     ]
    }
   ],
   "source": [
    "# Create Model  ---- variable 'alg' is set in the beginning, Key Inputs, section\n",
    "\n",
    "model = ' '               # this will be the ML model created by the algorithm. \n",
    "\n",
    "if alg == 'LR':           # variable 'alg' is set in the beginning, Key Inputs, section\n",
    "    y_testPredict,x_trainPredict,model,notes = LogRegNoPCA(X_train,y_train, X_test, y_test, notes,feat_list)\n",
    "\n",
    "if alg == 'LR-PCA':\n",
    "    y_testPredict,x_trainPredict,model,notes = LogRegPCA(X_train,y_train, X_test, notes)\n",
    "\n",
    "if alg == 'NN':\n",
    "    y_testPredict,x_trainPredict,model,notes = NN(X_train,y_train, X_test, notes)\n",
    "\n",
    "if alg == 'RFC':\n",
    "    y_testPredict,x_trainPredict,model,notes = RFC(X_train,y_train, X_test, notes,feat_list)\n",
    "\n",
    "if alg == 'LR-RFE':\n",
    "    y_testPredict,x_trainPredict,model,notes = LogRegRFE(X_train,y_train, X_test,y_test, notes, feat_list)\n",
    "\n",
    "if alg == 'ETC':\n",
    "    y_testPredict,x_trainPredict,model,notes = ExtraTrees(X_train,y_train, X_test,y_test, notes, feat_list)\n",
    "\n",
    "if alg == 'SVM':\n",
    "    y_testPredict,x_trainPredict,model,notes = SVM(X_train,y_train, X_test,y_test, notes, feat_list)\n",
    "\n",
    "if alg == 'SVMgrid':\n",
    "    y_testPredict,x_trainPredict,model,notes = SVMgrid(X_train,y_train, X_test,y_test, notes, feat_list)\n",
    "                \n",
    "        \n",
    "print(notes)\n",
    "print('model type:', type(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Accuracy of both the Train and Test data using model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_trainPredict: 97\n",
      "y_train: 97\n",
      "Train acc: 48.5 Test acc: 59.2\n"
     ]
    }
   ],
   "source": [
    "# Determine Accuracy of both the Train and Test data using model results\n",
    "print('x_trainPredict:', len(x_trainPredict))\n",
    "print('y_train:',len(y_train))\n",
    "test_acc, train_acc = 0,0\n",
    "for i in range(len(y_testPredict)):\n",
    "    if y_testPredict[i] == y_test.iloc[i]: test_acc +=1\n",
    "for i in range(len(x_trainPredict)):\n",
    "    if x_trainPredict[i] == y_train.iloc[i]: train_acc +=1 \n",
    "train_acc = round(train_acc/len(X_train)*100,1)\n",
    "test_acc = round(test_acc / len(y_test)*100, 1)\n",
    "print('Train acc:', train_acc, 'Test acc:', test_acc )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X and y: 49 49\n",
      "Predict Score (all data): 49.0\n",
      "\n",
      "Predictions, Year: 2017\n",
      "Predict Score (selected data) year:2017, week: 2, Correct %: nan, Missed:0\n",
      "Predict Score (selected data) year:2017, week: 3, Correct %: nan, Missed:0\n",
      "Predict Score (selected data) year:2017, week: 4, Correct %: nan, Missed:0\n",
      "Predict Score (selected data) year:2017, week: 5, Correct %: nan, Missed:0\n",
      "Predict Score (selected data) year:2017, week: 6, Correct %: nan, Missed:0\n",
      "Predict Score (selected data) year:2017, week: 7, Correct %: nan, Missed:0\n",
      "Predict Score (selected data) year:2017, week: 8, Correct %: nan, Missed:0\n",
      "Predict Score (selected data) year:2017, week: 9, Correct %: nan, Missed:0\n",
      "Predict Score (selected data) year:2017, week: 10, Correct %: nan, Missed:0\n",
      "Predict Score (selected data) year:2017, week: 11, Correct %: nan, Missed:0\n",
      "Errors totals: 0, Games total: 0, Error %: nan\n",
      "\n",
      "Details, Year: 2017, Week: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rernst\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "C:\\Users\\rernst\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in longlong_scalars\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Wk</th>\n",
       "      <th>Game</th>\n",
       "      <th>Ateam</th>\n",
       "      <th>AL5WinR</th>\n",
       "      <th>Bteam</th>\n",
       "      <th>BL5WinR</th>\n",
       "      <th>winner</th>\n",
       "      <th>predict</th>\n",
       "      <th>predict_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Year, Wk, Game, Ateam, AL5WinR, Bteam, BL5WinR, winner, predict, predict_score]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at some of the test predictions.\n",
    "predict_df = mdf[['Year','Wk','Game','Ateam','AL5WinR', 'Bteam','BL5WinR','winner' ]]\n",
    "predict_df = predict_df.drop(predict_df.index[0:len(x_trainPredict)])            # drop training games\n",
    "print('Length of X and y:', len(predict_df),len(y_testPredict))\n",
    "predict_df = predict_df.assign(predict = pd.Series(y_testPredict).values)   # add predictions for each test game\n",
    "predict_df['predict_score'] = np.where((predict_df['winner'] == predict_df['predict']), 1,0)  # 1 = prediction correct\n",
    "\n",
    "predict_Year = 2017\n",
    "errors_total = 0\n",
    "games_total = 0\n",
    "print('Predict Score (all data):', round(predict_df['predict_score'].sum() / len(predict_df)*100,1))\n",
    "temp = predict_df.filter(['Year','Wk','Ateam', 'Bteam', 'winner','predict'],axis=1)\n",
    "temp2 = temp.loc[temp['Year'] == predict_Year ]\n",
    "print('\\nPredictions, Year: {}'.format(predict_Year))\n",
    "for w in Weeks:\n",
    "    temp3 = temp2.loc[temp2['Wk'] == w]\n",
    "    temp3['predict_Errors'] =  np.where(temp3['winner']!= temp3['predict'],1,0)\n",
    "    print('Predict Score (selected data) year:{}, week: {}, Correct %: {}, Missed:{}'.format( predict_Year, w,\n",
    "                100 -round(temp3['predict_Errors'].sum()/len(temp3)*100, 1),\n",
    "                temp3['predict_Errors'].sum()))\n",
    "    games_total = games_total + temp3['predict_Errors'].count()\n",
    "    errors_total = errors_total + temp3['predict_Errors'].sum()\n",
    "print('Errors totals: {}, Games total: {}, Error %: {}'.format(errors_total, games_total, \n",
    "                    round((errors_total/games_total)*100,1)))\n",
    "temp3.tail()\n",
    "temp4 = predict_df[(predict_df.Year ==2017)  ] \n",
    "print('\\nDetails, Year: {}, Week: {}'.format('2017', '17'))\n",
    "temp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      "True Positives : 7   False Positives: 14\n",
      "False Negatives: 6   True Negatives:  22\n",
      "\n",
      "Note: True Positive: predict = A, actual = A; False Positive: predict = A, actual = B\n",
      "     False Negative: predict = B, actual = A; True Negative: predict = B, actual = B\n",
      "\n",
      "Test Accuracy:  59.2% \n",
      "Precision: 0.33, Recall: 0.54, f1-score: 0.41\n"
     ]
    }
   ],
   "source": [
    "matrix = confusion_matrix(y_test,y_testPredict)\n",
    "print('Confusion Matrix:\\n')\n",
    "true_pos  = int(matrix[0][0])\n",
    "false_pos = int(matrix[0][1])\n",
    "false_neg = int(matrix[1][0])\n",
    "true_neg  = int(matrix[1][1])\n",
    "print('True Positives : {}   False Positives: {}'.format(true_pos, false_pos))\n",
    "print('False Negatives: {}   True Negatives:  {}'.format(false_neg, true_neg))\n",
    "print('\\nNote: True Positive: predict = A, actual = A; False Positive: predict = A, actual = B')\n",
    "print('     False Negative: predict = B, actual = A; True Negative: predict = B, actual = B')\n",
    "print('\\nTest Accuracy: {: .1f}% '.format((true_pos+ true_neg)/ matrix.sum() * 100 ))\n",
    "\n",
    "precision = round(true_pos / (true_pos + false_pos),2)               # precision = tp / (tp + fp) [best = 1; worst = 0]\n",
    "recall = round(true_pos / (true_pos + false_neg),2)                  # recall = tp / (tp + fn) [best = 1]\n",
    "f1 = round(2 * (precision * recall) / (precision + recall),2) # weighted value of precision and recall\n",
    "print('Precision: {}, Recall: {}, f1-score: {}'.format( precision,recall,f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Report.  Optionally, save Report.  Optionally, save Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Report (key fields):\n",
      "TestAcc, TrainAcc, Notes\n",
      "59.2 48.5 Notes: ** Train / Test Split traditional at: 0.33 ** NN, # of layers:2 Nodes/layer:[12, 8]\n"
     ]
    }
   ],
   "source": [
    "# Create Test Report\n",
    "def array2str(yarray):\n",
    "    \"\"\" input is a numpy array, output a comma separate string\"\"\"\n",
    "    ystr = ''\n",
    "    for iy in range(len(yarray)):   # convert the array to set of items seperated by commas so that it can be in db\n",
    "        if ystr == '': ystr = str(yarray[iy])\n",
    "        else: ystr = ystr + ', ' + str(yarray[iy]) \n",
    "    return ystr\n",
    "\n",
    "# Set-up data for recording\n",
    "\n",
    "runDate = dt.datetime.today().strftime(\"%m/%d/%Y %H:%M\")\n",
    "script = 'ML-Modeling-v4'\n",
    "project = 'ai_affinity'\n",
    "period1 = array2str(Years)   #array of years to string of comma sep years for database\n",
    "period2 = array2str(Weeks)   #array of weeks to string of comma sep weeks for database\n",
    "testsize =   round((len(X_test) / (len(X_test)+len(X_train)))*100,1)     # size of test dataset (as a % of all input)\n",
    "\n",
    "print('Test Report (key fields):')\n",
    "print('TestAcc, TrainAcc, Notes')\n",
    "print( test_acc, train_acc, notes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Report saved.\n",
      "\n",
      "Ended\n"
     ]
    }
   ],
   "source": [
    "#  Save test results to TestDB    \n",
    "\n",
    "if saveRpt == 'Y':                           # this is set at beginning (key inputs section)\n",
    "    # Insert into TestDB (as record in 'test' table)\n",
    "    cur.execute(\"\"\"INSERT OR IGNORE INTO test \n",
    "                (project,date,inCnt,testAcc,trainAcc,\n",
    "                period1,period2,num_of_feat,features, testsize,alg,script,notes,\n",
    "                truePos, falsePos, falseNeg, trueNeg,precision,recall,f1) \n",
    "                VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)\"\"\" , \n",
    "                (project,runDate,inCnt,test_acc,train_acc,\n",
    "                 period1,period2,Num_of_feat,features,testsize,alg,script,notes,\n",
    "                 true_pos, false_pos, false_neg, true_neg, precision, recall, f1 ))\n",
    "    print ('\\nReport saved.')\n",
    "\n",
    "\n",
    "conn.commit()                     # flush to database \n",
    "conn.close()                      # Close database\n",
    "print('\\nEnded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model type being saved: type: <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>\n",
      "\n",
      "Model saved. Name: Model-NN-13-20191119-0813.sav\n"
     ]
    }
   ],
   "source": [
    "#  Save model  naming convention: 'Model'-'Alg'-'FeatureSet#'-'Date&time'  \n",
    "\n",
    "if save_model == 'Y':             # This is set at begining of script (key inputs section)\n",
    "    print('Model type being saved:',  'type:', type(model))\n",
    "    name = 'Model-' + alg + '-' + str(features) +'-' + str(dt.datetime.today().strftime(\"%Y%m%d-%H%M\"))+ '.sav'  #name of file  \n",
    "    joblib.dump(model,  name)\n",
    "    print ('\\nModel saved. Name:',  name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
